{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reanalyzing Brewster and Franz data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pboc.plotting\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "import mwc_growth as mwc\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matlab.engine as matlab\n",
    "import scipy.optimize\n",
    "import glob\n",
    "import seaborn as sns\n",
    "eng = matlab.start_matlab()\n",
    "colors = pboc.plotting.set_plotting_style()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the calibration factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cell_to_dict(file, eng, add_props=None, excluded_props=None):\n",
    "    \"\"\"\n",
    "    Reads a single cell file and produces a dictionary containing\n",
    "    the properties of interest.\n",
    "\n",
    "    The returned properties are\n",
    "    * birth - frame number at which the cell was born.\n",
    "    * death - frame number at which the cell died.\n",
    "    * divide - bool for an observed cell division.\n",
    "    * ID - integer ID number of the cell.\n",
    "    * motherID - integer ID number of the mother cell.\n",
    "    * sisterID - integer ID number of the sister cell.\n",
    "    * birth_fluo - fluorescence value at the cell's birth.\n",
    "    * death_fluo - fluorescence value at the cell's death.\n",
    "    * daughter_1_ID - integer ID number of the first daughter.\n",
    "    * daughter_2_ID - integer ID number of the second daughter.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file: str\n",
    "        Path of the cell file. This must be in a `.mat` format.\n",
    "    eng: MATLAB engine object\n",
    "        Engine of running matlab session.\n",
    "    add_props : dict, default None\n",
    "        Dictionary of additional properties (not found in the mat file)\n",
    "        to be included in the returned dictionary.\n",
    "    excluded_props: list of str\n",
    "        Properties of cell.mat file to be ignored. These must be\n",
    "        exactly how they are defined in the cell file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cell_dict : dictionary\n",
    "        Dictionary of all extracted properties from the cell files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the supplied file is actually a .mat and other types are correct.\n",
    "    if file.split('.')[-1] != 'mat':\n",
    "        raise TypeError(\"supplied file {0} is not a `.mat` file.\".format(file))\n",
    "    if add_props is not None and type(add_props) is not dict:\n",
    "        raise TypeError(\n",
    "            \"add_props is {0} and not dict.\".format(type(add_props)))\n",
    "    if excluded_props is not None and type(excluded_props) is not list:\n",
    "        raise TypeError(\n",
    "            \"add_props must be list. Type is currently {0}.\".format(type(excluded_props)))\n",
    "\n",
    "    # Define the values of interest.\n",
    "    vals = ['birth', 'death', 'divide', 'ID', 'motherID', 'sisterID',\n",
    "            'daughter_1_ID', 'daughter_2_ID', 'birth_fluo', 'death_fluo', 'birth_area', 'death_area']\n",
    "\n",
    "    # Load the mat file using MATLAB.\n",
    "    eng.workspace['f'] = file\n",
    "    mat = eng.eval('load(f)')\n",
    "\n",
    "    # Assemble the dictionary for constant properties.\n",
    "    cell_dict = {v: mat[v] for v in vals[:-6]}\n",
    "    daughters = np.array(mat['daughterID'])\n",
    "\n",
    "    # Determine  if daughters were produced. If not, change ID to NaN.\n",
    "    if len(daughters) == 0:\n",
    "        daughter_1, daughter_2 = None,  None\n",
    "    else:\n",
    "        daughter_1, daughter_2 = daughters[0]\n",
    "    cell_dict['daughter_1_ID'] = daughter_1\n",
    "    cell_dict['daughter_2_ID'] = daughter_2\n",
    "\n",
    "    # Extract fluorescence information -- This is a bit gross but checked.\n",
    "    # Get number of fluorescence channels.\n",
    "    fluo_channels = [f for f in mat['CellA'][0].keys() if 'fl' in f]\n",
    "    n_channels = int(len(fluo_channels) / 3)\n",
    "    for n in range(n_channels):\n",
    "        _n = n + 1\n",
    "        try:\n",
    "            fluo = [mat['CellA'][i]['fl{0}'.format(\n",
    "                _n)]['sum'] for i, _ in enumerate(mat['CellA'])]\n",
    "            bg = [mat['CellA'][i]['fl{0}'.format(_n)]['bg'] for i, _ in enumerate(mat['CellA'])]\n",
    "            nonzero = np.where(np.array(fluo) > 0)[0]\n",
    "            num_exposures = len(nonzero)\n",
    "            cell_dict['fluor{0}_bg_birth_fluo'.format(_n)] = bg[nonzero.min()]\n",
    "            cell_dict['fluor{0}_bg_death_fluo'.format(_n)] = bg[nonzero.max()]\n",
    "            cell_dict['fluor{0}_birth_fluo'.format(_n)] = fluo[nonzero.min()]\n",
    "            cell_dict['fluor{0}_death_fluo'.format(_n)] = fluo[nonzero.max()]\n",
    "            cell_dict['birth_area'] = mat['CellA'][nonzero.min()]['coord']['A']\n",
    "            cell_dict['death_area'] = mat['CellA'][nonzero.max()]['coord']['A']\n",
    "        except:\n",
    "            cell_dict['fluor{0}_birth_fluo'.format(_n)] = 0\n",
    "            cell_dict['fluor{0}_death_fluo'.format(_n)] = 0\n",
    "            cell_dict['birth_area'] = mat['CellA'][0]['coord']['A']\n",
    "            cell_dict['death_area'] = mat['CellA'][-1]['coord']['A']\n",
    "            cell_dict['fluor{0}_bg_birth_fluo'.format(_n)] = 0\n",
    "            cell_dict['fluor{0}_bg_death_fluo'.format(_n)] = 0\n",
    "            num_exposures = 0\n",
    "            cell_dict['fluor{0}_num_exposures'.format(_n)] = num_exposures\n",
    "\n",
    "    # Deal with exclusion and addition of props.\n",
    "    if excluded_props is not None:\n",
    "        new_dict = {}\n",
    "        keys = cell_dict.keys()\n",
    "        for key in keys:\n",
    "            if key not in excluded_props:\n",
    "                new_dict[key] = cell_dict[key]\n",
    "        cell_dict = new_dict\n",
    "    if add_props is not None:\n",
    "        for key in add_props.keys():\n",
    "            cell_dict[key] = add_props[key]\n",
    "\n",
    "    # Return the cell dictionary.\n",
    "    return cell_dict\n",
    "\n",
    "\n",
    "def parse_cell_files(files, eng, verbose=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Executes cell_to_dict across a list of files and returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if type(files) is not list:\n",
    "        raise TypeError(\"'files' is type {0} not list.\".format(type(files)))\n",
    "    if verbose:\n",
    "        files = tqdm.tqdm(files)\n",
    "    for i, f in enumerate(files):\n",
    "        cell_dict = cell_to_dict(f, eng, **kwargs)\n",
    "        if i == 0:\n",
    "            keys = cell_dict.keys()\n",
    "            df = pd.DataFrame([], columns=keys)\n",
    "            df = df.append(cell_dict, ignore_index=True)\n",
    "        else:\n",
    "            df = df.append(cell_dict, ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the data directory.\n",
    "data_dir = '../../../data/images/20121115_37C_glucose_O1_dilution/'\n",
    "\n",
    "# Grab the growth positions.\n",
    "growth_pos = glob.glob('{0}20121115_growth*/xy*'.format(data_dir))\n",
    "\n",
    "# Set up a list to store the resultant dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate through each position and load the cell files into python.\n",
    "for i, pos in enumerate(growth_pos):\n",
    "    \n",
    "    # Load the cell files.\n",
    "    cell_files = glob.glob('{0}/cell/*ell*.mat'.format(pos))\n",
    "    \n",
    "    # Parse each cell file and get a resulting dataframe.\n",
    "    position = int(pos.split('/')[-1].split('xy')[1])\n",
    "    _df = parse_cell_files(cell_files, eng=eng, add_props=dict(position=position),\n",
    "                          verbose=True)\n",
    "   \n",
    "    # Append to the storage list.\n",
    "    dfs.append(_df)\n",
    "    \n",
    "# Concatenate into a single data frame.\n",
    "growth_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the other data sets.\n",
    "other_sets = glob.glob('{0}*autofluorescence*'.format(data_dir))\n",
    "desired_props = ['fluor1_birth_fluo', 'fluo2_birth_fluo', 'birth_area']\n",
    "dfs = []\n",
    "for i, samp in enumerate(other_sets):\n",
    "        # Get all of the positions in each folder.\n",
    "        positions = glob.glob('{0}/xy*/'.format(samp))\n",
    "    \n",
    "        # Loop through each position.\n",
    "        for j, pos in enumerate(positions):\n",
    "            # Get a list of all cell files.\n",
    "            cell_files = glob.glob('{0}/cell/*ell*.mat'.format(pos))\n",
    "        \n",
    "            # Parse them and exclude properties\n",
    "            _df = parse_cell_files(cell_files, eng=eng, add_props=dict(position=j, strain='auto'),\n",
    "                                   verbose=True)\n",
    "            dfs.append(_df)\n",
    "         \n",
    "snap_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean autofluorescence value. \n",
    "mean_auto_cherry = np.mean((snap_df['fluor2_birth_fluo'] / snap_df['birth_area']))\n",
    "mean_auto_yfp = np.mean((snap_df['fluor1_birth_fluo'] / snap_df['birth_area']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the triads is easier this time as we have just one snap at the end with a fluorescence image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max frame.\n",
    "max_frame = np.sort(growth_df['death'].unique())[-1]\n",
    "measured = growth_df[(growth_df['death']==max_frame)]\n",
    "\n",
    "# Set the storage vectors.\n",
    "I_1, I_2, summed, sq_diff = [], [], [], []\n",
    "\n",
    "# Group the data by mother ID\n",
    "grouped = measured.groupby(['position', 'motherID'])\n",
    "for g, d in grouped:\n",
    "    if len(d) == 2:\n",
    "        daughters = d['fluor2_death_fluo'].values - d['death_area'].values * mean_auto_cherry \n",
    "        if (daughters >= 0).all():\n",
    "            I_1.append(daughters[0])\n",
    "            I_2.append(daughters[1])\n",
    "            summed.append(daughters.sum())\n",
    "            sq_diff.append((daughters[0] - daughters[1])**2)\n",
    "\n",
    "I_1 = np.array(I_1)\n",
    "I_2 = np.array(I_2)\n",
    "I_tot = I_1 + I_2\n",
    "\n",
    "ratios = []\n",
    "for i, j in zip(I_1, I_2):\n",
    "    ratios.append(np.abs(i / (i + j)))\n",
    "print(np.mean(ratios)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.sort(ratios), np.arange(len(ratios)) / len(ratios)\n",
    "plt.vlines(np.mean(ratios), 0, 1.0, 'r')\n",
    "plt.plot(x,y, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import pboc.mcmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(pboc.mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicLogPosterior(pm.Continuous):\n",
    "    def __init__(self, I_1=None, I_2=None, *args, **kwargs):\n",
    "        super(DeterministicLogPosterior, self).__init__(*args, **kwargs)\n",
    "    def logp(self, value, *args):\n",
    "        n1 = I_1 / value\n",
    "        n2 = I_2 / value\n",
    "        ntot = n1 + n2\n",
    "        k = len(I_1)\n",
    "        binom = tt.sum(tt.gammaln(ntot+1)) - tt.sum(tt.gammaln(n1+1)) -tt.sum(tt.gammaln(n2+1))\n",
    "        return -k * tt.log(value) + binom - tt.sum(ntot) * tt.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    alpha = DeterministicLogPosterior('alpha', I_1, I_2, testval=100)\n",
    "    trace = pm.sample(tune=1000, draws=2000, njobs=4)\n",
    "    trace_df = pboc.mcmc.trace_to_dataframe(trace, model)\n",
    "    stats = pboc.mcmc.compute_statistics(trace_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_opt = stats['mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bin the data for plotting.\n",
    "def binning_mean(data, bin_width, sort_values=False):\n",
    "    \"\"\"\n",
    "    Computes the mean value of squared difference and summed intensity of the \n",
    "    supplied data with a given number of events per bin. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "        A dataframe containing the intensities of the daughter cells and the sum\n",
    "        total intensity.\n",
    "    bin_width : int\n",
    "        Number of events to consider per bin.\n",
    "    sort_values : bool\n",
    "        If True, the supplied data will be sorted in increasing order of the \n",
    "        sum total fluorescence. Default is False.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mean_sq_diff, mean_sum : 1d-arrays\n",
    "        Arrays of the mean square difference value and the mean summed intensity \n",
    "        in a given bin width.  \n",
    "    \"\"\"\n",
    "    # Sort the data if necessary.\n",
    "    if sort_values:\n",
    "        data = data.sort_values(by='I_tot')\n",
    "        \n",
    "    # Set the bins. \n",
    "    bins = np.arange(0, len(data) + bin_width, bin_width)\n",
    "    \n",
    "    # Compute the means. \n",
    "    mean_sq_diff = [np.mean((data.iloc[bins[i-1]:bins[i]+1]['I_1'] -\\\n",
    "                         data.iloc[bins[i-1]:bins[i]+1]['I_2'])**2) for i in range(1, len(bins))]\n",
    "    mean_I_tot = [data.iloc[bins[i-1]:bins[i]+1]['I_tot'].mean() for i in range(1, len(bins))] \n",
    "    return [np.array(mean_sq_diff), np.array(mean_I_tot)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the data frame.\n",
    "binning_df = pd.DataFrame(np.array([I_1, I_2, I_tot]).T, columns=['I_1', 'I_2', 'I_tot'])\n",
    "\n",
    "# Bin the data. \n",
    "bin_size =  50 \n",
    "mean_sq_diff, mean_I_tot = binning_mean(binning_df, bin_width=bin_size, sort_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make the scatter plot.\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('$I_{tot}$ [a.u.]')\n",
    "ax.set_ylabel('$(I_1 - I_2)^2$ [a.u.]')\n",
    "\n",
    "# Plot the data\n",
    "_ = ax.plot(summed, sq_diff, '.', color='slategray', label='data')\n",
    "\n",
    "# Plot the binned data.\n",
    "_ = ax.plot(mean_I_tot, mean_sq_diff, 'o', color='dodgerblue', label='binned data')\n",
    "\n",
    "# Plot the theory curve. \n",
    "# alpha_opt = stats['mode'].values\n",
    "I_tot_range = np.logspace(2,6, 500)\n",
    "# theo = alpha_opt * I_tot_range\n",
    "# _ = ax.plot(I_tot_range, theo, '-', color='tomato', label='fit')\n",
    "\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit by binning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try fitting the calibration factor using the binning approach.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(alpha, sq_diff, summed_int, neg=True):\n",
    "    \"\"\"\n",
    "    Computes the log posterior distribution for linear regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        Value of the calibration factor in arbitrary units.\n",
    "    I_tot : pandas DataFrame or array\n",
    "        The summed value of the daughter intensities.\n",
    "    neg: bool\n",
    "        If True, the negative of the log posterior is returned. Defaults is True. \n",
    "    Returns\n",
    "    --------\n",
    "    lp : 1d-array\n",
    "        The value of the log posterior at a given alpha. \n",
    "\n",
    "    \"\"\"\n",
    "    k = len(summed_int)\n",
    "    lp = -(k/2) * np.log(np.sum((sq_diff - alpha * summed_int)**2))\n",
    "    if neg is True:\n",
    "        prefactor = -1\n",
    "    else:\n",
    "        prefactor = 1\n",
    "    return prefactor * lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the calibration factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.workspace['f'] = '/Users/gchure/Desktop/dilution_data.mat'\n",
    "mat = eng.eval('load(f)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = mat['rdif']\n",
    "tot = mat['rtot']\n",
    "I2 = (tot - np.sqrt(dif)) / 2\n",
    "I1 = np.sqrt(dif) + I2\n",
    "I1 = I1[0]\n",
    "I2 = I2[0]\n",
    "popt = scipy.optimize.minimize_scalar(deterministic_log_posterior, args=(I1, I2, I1+I2, True))\n",
    "brewster_df = pd.DataFrame(np.array([I1, I2, I1+I2]).T, columns=['I_1', 'I_2', 'I_tot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "_ = ax.plot(brewster_df['I_tot'], (brewster_df['I_1'] - brewster_df['I_2'])**2, 'k.', alpha=0.5)\n",
    "_ = ax.plot(I_1 + I_2, (I_1 - I_2)**2, '.', color='tomato', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    return np.sort(data), np.arange(0, len(data), 1) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_df_small = snap_df\n",
    "\n",
    "# Subtract the autofluorescence from each channel.\n",
    "snap_df_small.loc[:, 'fluor2_sub'] = snap_df_small['fluor2_birth_fluo'] - snap_df_small['birth_area'] * mean_auto_yfp \n",
    "snap_df_small.loc[:, 'fluor1_sub'] = snap_df_small['fluor1_birth_fluo'] - snap_df_small['birth_area'] * mean_auto_cherry\n",
    "\n",
    "# Compute the mean delta for each.\n",
    "mean_delta_yfp = np.mean(snap_df_small[snap_df_small['strain']=='deltaLacI']['fluor2_sub'] / snap_df_small[snap_df_small['strain']=='deltaLacI']['birth_area'])\n",
    "mean_delta_cherry = np.mean(snap_df_small[snap_df_small['strain']=='deltaTetR']['fluor1_sub'] / snap_df_small[snap_df_small['strain']=='deltaTetR']['birth_area'])\n",
    "\n",
    "# Look at only the dilution strain and calculate the fold change.\n",
    "dilution_strain = snap_df_small[snap_df_small['strain']=='dilution']\n",
    "fold_change = []\n",
    "repressors = []\n",
    "grouped = dilution_strain.groupby('atc')\n",
    "for g, d in grouped:\n",
    "    mean_yfp = np.mean(d['fluor2_sub'] / d['birth_area'])\n",
    "    fold_change.append(mean_yfp / mean_delta_yfp)\n",
    "    mean_repressors = np.mean(d['fluor1_sub']) / alpha_opt\n",
    "    repressors.append(mean_repressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction.\n",
    "rep_range = np.logspace(-1, 3, 300)\n",
    "fc_theo = (1 +  (rep_range / 4.6E6) * np.exp(13.9))**-1\n",
    "\n",
    "# Generate the plot\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('number of repressors')\n",
    "ax.set_ylabel('foldchange')\n",
    "all_fc = dilution_strain['fluor2_sub'] / mean_delta_yfp\n",
    "all_rep = dilution_strain['fluor1_sub'] / alpha_opt\n",
    "# Plot the prediction.\n",
    "_ = ax.plot(rep_range, fc_theo, color='slategray', label='theory')\n",
    "\n",
    "# Plot the data\n",
    "_ = ax.plot(np.array(repressors), fold_change, 'o', color='tomato', label='data')\n",
    "# _ = ax.plot(all_rep, all_fc, ',', color='dodgerblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the calibration factor (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import bokeh.io \n",
    "import bokeh.plotting\n",
    "import bokeh_catplot as bkcat \n",
    "import scipy.optimize\n",
    "import mwc.stats \n",
    "import mwc.bayes \n",
    "import mwc.viz\n",
    "import bokeh.models\n",
    "import bokeh.transform\n",
    "import tqdm\n",
    "import bokeh.palettes\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import statsmodels.tools.numdiff as smnd\n",
    "import tqdm\n",
    "colors, color_list = mwc.viz.bokeh_theme()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ec9b6f17a0c5c7c8560abb5a3db50f1e NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precompiled model not found. Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /var/folders/2q/lvh2zsws3lxckq8xtkn_84z80000gn/T/tmpxn7h_dp3/stanfit4anon_model_ec9b6f17a0c5c7c8560abb5a3db50f1e_5865823034373752244.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# Load the snapshots\n",
    "snaps = pd.read_csv('../../data/raw_compiled_snaps.csv')\n",
    "\n",
    "# Load the lineages\n",
    "lineages = pd.read_csv('../../data/raw_compiled_lineages.csv')\n",
    "\n",
    "# Apply morphology filters to both. \n",
    "min_size = 0.5 / 0.065**2\n",
    "max_size = 5 / 0.065**2\n",
    "snaps = mwc.process.morphological_filter(snaps, area_bounds=[0.5, 5], \n",
    "                                         ar_bounds=[0, 0.8], ip_dist=0.065)\n",
    "lineages = lineages[(lineages['area_1'] >= min_size) & (lineages['area_2'] >= min_size) &\n",
    "                   (lineages['area_1'] <= max_size) & (lineages['area_2'] <= max_size)]\n",
    "\n",
    "# Drop error frames \n",
    "lineages['error_frame'] = np.nan_to_num(lineages['error_frame'])\n",
    "lineages = lineages[lineages['error_frame'] == 0].copy()\n",
    "\n",
    "\n",
    "# Load the hierarchical model. \n",
    "# model = mwc.bayes.StanModel('../stan/calibration_factor.stan') #, force_compile=True)\n",
    "model = mwc.bayes.StanModel('../stan/hierarchical_calibration_factor.stan', force_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with examining **only** the glucose sample\n",
    "samp = lineages[(lineages['carbon']=='acetate') & (lineages['temp']==37)].copy()\n",
    "auto_samp = snaps[(snaps['carbon']=='acetate') & (snaps['temp']==37) & (snaps['strain']=='auto')].copy()\n",
    "\n",
    "# Iterate through all of the days and run numbers and subratcting the chosen value\n",
    "funcs = {'mean_auto':np.mean, 'median_auto':np.mean}\n",
    "for g, d in samp.groupby(['date', 'run_number']):\n",
    "    _auto = auto_samp[(auto_samp['date']==g[0]) &\n",
    "                     (auto_samp['run_number']==g[1])]['fluor2_mean_death'].values\n",
    "    # Compute the summary statistica and add it to the samp\n",
    "    for v, f in funcs.items():\n",
    "        auto_mch = f(_auto)\n",
    "        samp.loc[(samp['date']==g[0]) & (samp['run_number']==g[1]), v] = f(_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning sampling...\n"
     ]
    }
   ],
   "source": [
    "# Perform the background subtraction and compute integrated intensity. \n",
    "samp['I_1_tot'] = samp['area_1'] * (samp['I_1'].values - samp['median_auto'])\n",
    "samp['I_2_tot'] = samp['area_2'] * (samp['I_2'].values - samp['median_auto'])\n",
    "\n",
    "# Remove unphysical values. \n",
    "samp = samp[(samp['I_1_tot'] >=0) & (samp['I_2_tot'] >= 0)]\n",
    "\n",
    "# Add identifiers for each category.\n",
    "samp['day_idx'] = samp.groupby(['date']).ngroup() + 1\n",
    "samp['rep_idx'] = samp.groupby(['date', 'run_number']).ngroup() + 1\n",
    "\n",
    "# Create the mapping between rep_idx and day\n",
    "rep_map = []\n",
    "for g, d in samp.groupby('rep_idx'):\n",
    "    rep_map.append(d['day_idx'].unique()[0])\n",
    "    \n",
    "# Set up the data dictionary. \n",
    "data_dict = {'J_day':samp['day_idx'].max(), \n",
    "             'K_rep': samp['rep_idx'].max(), \n",
    "             'N_fluct': len(samp),\n",
    "             'day_idx': rep_map,\n",
    "             'rep_idx': samp['rep_idx'].values,\n",
    "             'I_1':samp['I_1_tot'].values,\n",
    "             'I_2':samp['I_2_tot'].values}\n",
    "\n",
    "# Sample the motherfucker\n",
    "fit, mcmc_samples = model.sample(data_dict, iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_ec9b6f17a0c5c7c8560abb5a3db50f1e.\n",
       "4 chains, each with iter=500; warmup=250; thin=1; \n",
       "post-warmup draws per chain=250, total post-warmup draws=1000.\n",
       "\n",
       "                  mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "tau_alpha         23.3   14.76  20.99  -3.55   1.46  25.42  43.02  47.39      2  19.48\n",
       "alpha_1         159.66   11.34  16.66 126.87 147.83 165.24 171.89 177.05      2   5.81\n",
       "alpha_2_raw[1]   -0.25    0.77   1.09  -1.52  -1.37  -0.25   0.84   1.03      2  75.82\n",
       "alpha_2_raw[2]    0.38    0.34   0.48  -0.36  -0.09   0.44   0.85   0.89      2  15.42\n",
       "alpha_2_raw[3]   -1.18    0.87   1.24  -2.75  -2.49  -1.21  -0.17   0.61      2   10.7\n",
       "alpha_2_raw[4]    0.17    0.58   0.83  -1.01  -0.57   0.17   0.75   1.38      2  10.72\n",
       "alpha_2_raw[5]   -0.06    0.86   1.23  -2.09  -0.73  -0.07   1.03   1.58      2   8.81\n",
       "alpha_2_raw[6]    0.16    0.66   0.93  -1.18  -0.65   0.18   0.97   1.44      2 362.37\n",
       "alpha_2_raw[7]   -0.46    0.86   1.21  -1.95  -1.68  -0.41   0.74   0.92      2 2155.9\n",
       "alpha_2_raw[8]   -0.28    0.74   1.05  -1.97  -1.16  -0.07   0.71   0.85      2  23.36\n",
       "alpha_2_raw[9]    1.34    1.03   1.52  -1.16   0.64   1.42   2.84   3.24      2   5.25\n",
       "alpha_2_raw[10]   0.97    0.46   0.64    0.2   0.39   0.86   1.56   1.93      2 1055.3\n",
       "alpha_3_raw[1]   -0.36    0.33   0.47  -0.98  -0.78  -0.42   0.08   0.34      2  50.28\n",
       "alpha_3_raw[2]   -0.11    0.83   1.18  -1.38  -1.33  -0.13   1.07   1.24      2  38.29\n",
       "alpha_3_raw[3]   -0.06    0.37   0.54  -1.04  -0.51   0.21    0.3   0.45      2   5.76\n",
       "alpha_3_raw[4]   -0.84    0.86   1.22  -2.02  -1.88  -1.39   0.27   1.16      2  18.64\n",
       "alpha_3_raw[5]    0.61    0.97   1.39  -1.71  -0.36   0.84   1.86   2.28      2  10.12\n",
       "alpha_3_raw[6]    1.16    0.19   0.27   0.71   0.93   1.26   1.38   1.41      2  60.85\n",
       "alpha_3_raw[7]    0.67    0.34   0.48  -0.09   0.23   0.82   1.08   1.15      2  876.6\n",
       "alpha_3_raw[8]   -0.72    0.77   1.09  -1.98  -1.56  -0.92   0.25    1.0      2  27.19\n",
       "alpha_3_raw[9]    0.89    1.88   2.69  -4.08  -0.56   2.27   2.75    2.9      2  10.55\n",
       "alpha_3_raw[10]   0.02    0.22   0.31  -0.29  -0.23  -0.08   0.29   0.53      2 308.12\n",
       "alpha_2[1]       175.2   18.06  26.01 147.27 158.11 163.79 200.23 219.36      2   9.57\n",
       "alpha_2[2]      170.86    2.99   5.96 160.16 166.49 172.34 176.26  178.7      4    2.2\n",
       "alpha_2[3]      125.98   33.52  48.89  12.83  92.58 149.04 158.34  176.6      2   7.06\n",
       "alpha_2[4]       154.5    8.41  12.82 133.93 141.22 157.29 161.91 175.45      2   3.96\n",
       "alpha_2[5]       180.5    9.25  13.54 163.33 167.88 178.76  192.1 202.28      2   6.12\n",
       "alpha_2[6]      162.46   39.01  55.47  70.95 120.38 165.13 208.18 237.79      2  16.38\n",
       "alpha_2[7]      124.14   34.79  49.66  34.26  79.71 140.95 170.95 175.43      2  12.54\n",
       "alpha_2[8]      173.68   16.11  23.04 147.41 157.12 167.35  195.6 211.17      2  10.08\n",
       "alpha_2[9]      207.62   27.51  39.15  163.9 178.53 194.42 241.33  280.9      2  13.82\n",
       "alpha_2[10]      187.3   29.44  41.91 155.42  158.4 167.47 218.14 261.13      2  13.71\n",
       "alpha_3[1]      175.59   14.72  21.46 140.37 163.43 172.24 194.53  209.6      2   8.07\n",
       "alpha_3[2]      168.95   24.05  34.37 106.65 145.17 180.67 194.34  209.4      2  12.81\n",
       "alpha_3[3]      117.41   29.54  44.59   8.95  83.51 130.97 156.75  176.7      2   4.89\n",
       "alpha_3[4]      116.99   36.95  52.53  57.33  62.29 117.31  173.7  176.9      2  16.07\n",
       "alpha_3[5]      212.66   34.84  49.66 173.26 176.91 179.99 256.52 310.41      2  13.78\n",
       "alpha_3[6]      187.15   34.44  48.99 137.34 150.51 176.79 224.03 270.82      2  14.76\n",
       "alpha_3[7]      145.67   21.99  31.56  88.43 119.11 153.16 178.16 181.93      2   9.33\n",
       "alpha_3[8]      155.95   25.63  36.35  91.55 132.83  174.2 180.92 182.28      2  19.84\n",
       "alpha_3[9]      275.02   61.95  88.24 178.31  182.5 255.99 365.45 413.06      2  15.76\n",
       "alpha_3[10]      189.9   23.58  33.63 156.37  167.4 176.34 215.92 247.65      2  11.44\n",
       "lp__            -7.5e7   3.9e5  6.0e5 -7.5e7 -7.5e7 -7.5e7 -7.4e7 -7.3e7      2   4.07\n",
       "\n",
       "Samples were drawn using NUTS at Tue Jul 23 15:14:19 2019.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:01<00:16,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:07<00:28,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:10<00:25,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:13<00:23,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:15<00:19,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:18<00:16,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:19<00:11,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [00:21<00:08,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:23<00:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:23<00:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:29<00:02,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n",
      "Beginning sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:32<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished sampling!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats_dfs = pd.DataFrame([])\n",
    "for g, d in tqdm.tqdm(samp.groupby(['date', 'run_number'])):\n",
    "    # Set up the data dict and sample\n",
    "    data_dict = {'N': len(d), 'I1':d['I_1_tot'], 'I2':d['I_2_tot']}\n",
    "    _, samples = model.sample(data_dict, iter=2000)\n",
    "\n",
    "    # Compute the important stats of alpha. \n",
    "    mean_alpha = np.median(samples['alpha'])\n",
    "    alpha_min,alpha_max = mwc.stats.compute_hpd(samples['alpha'], 0.95)\n",
    "    stats_dfs = stats_dfs.append({'date':g[0], 'run_number':g[1], \n",
    "                                  'mean_alpha':mean_alpha,\n",
    "                                  'alpha_min':alpha_min, \n",
    "                                  'alpha_max':alpha_max}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_max</th>\n",
       "      <th>alpha_min</th>\n",
       "      <th>date</th>\n",
       "      <th>mean_alpha</th>\n",
       "      <th>run_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.711477</td>\n",
       "      <td>61.518947</td>\n",
       "      <td>20181021.0</td>\n",
       "      <td>62.635996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.788854</td>\n",
       "      <td>43.608250</td>\n",
       "      <td>20181024.0</td>\n",
       "      <td>44.694171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.606496</td>\n",
       "      <td>50.471268</td>\n",
       "      <td>20181025.0</td>\n",
       "      <td>51.460419</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.058422</td>\n",
       "      <td>59.921620</td>\n",
       "      <td>20181121.0</td>\n",
       "      <td>61.023441</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.151051</td>\n",
       "      <td>52.839682</td>\n",
       "      <td>20181127.0</td>\n",
       "      <td>53.973398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.746332</td>\n",
       "      <td>34.516709</td>\n",
       "      <td>20190102.0</td>\n",
       "      <td>35.698389</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.631794</td>\n",
       "      <td>24.430548</td>\n",
       "      <td>20190102.0</td>\n",
       "      <td>25.528411</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47.121473</td>\n",
       "      <td>44.891318</td>\n",
       "      <td>20190103.0</td>\n",
       "      <td>46.051134</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.079966</td>\n",
       "      <td>38.803902</td>\n",
       "      <td>20190103.0</td>\n",
       "      <td>39.954739</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.985518</td>\n",
       "      <td>33.644575</td>\n",
       "      <td>20190104.0</td>\n",
       "      <td>34.779607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.024214</td>\n",
       "      <td>74.803780</td>\n",
       "      <td>20190611.0</td>\n",
       "      <td>75.877637</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.927477</td>\n",
       "      <td>75.685541</td>\n",
       "      <td>20190617.0</td>\n",
       "      <td>76.873825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha_max  alpha_min        date  mean_alpha  run_number\n",
       "0   63.711477  61.518947  20181021.0   62.635996         1.0\n",
       "1   45.788854  43.608250  20181024.0   44.694171         1.0\n",
       "2   52.606496  50.471268  20181025.0   51.460419         1.0\n",
       "3   62.058422  59.921620  20181121.0   61.023441         1.0\n",
       "4   55.151051  52.839682  20181127.0   53.973398         1.0\n",
       "5   36.746332  34.516709  20190102.0   35.698389         1.0\n",
       "6   26.631794  24.430548  20190102.0   25.528411         2.0\n",
       "7   47.121473  44.891318  20190103.0   46.051134         1.0\n",
       "8   41.079966  38.803902  20190103.0   39.954739         2.0\n",
       "9   35.985518  33.644575  20190104.0   34.779607         1.0\n",
       "10  77.024214  74.803780  20190611.0   75.877637         1.0\n",
       "11  77.927477  75.685541  20190617.0   76.873825         1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

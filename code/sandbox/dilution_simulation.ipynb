{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Simulating the dilution experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"8351f4fb-f466-49d0-a980-b8441cb1bc73\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"8351f4fb-f466-49d0-a980-b8441cb1bc73\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete window._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"8351f4fb-f466-49d0-a980-b8441cb1bc73\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '8351f4fb-f466-49d0-a980-b8441cb1bc73' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"8351f4fb-f466-49d0-a980-b8441cb1bc73\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.6.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.6.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"8351f4fb-f466-49d0-a980-b8441cb1bc73\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "import scipy.special\n",
    "\n",
    "# Display graphics in this notebook\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the problem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seed the RNG for reproducibility. \n",
    "np.random.seed(666)  # number of the beast\n",
    "\n",
    "# Define some parameters. \n",
    "alpha = 50 # in arbitrary units\n",
    "int_range = alpha * np.logspace(0, 4, 100)  # I_tot range for the calculation.\n",
    "min_Ntot = 1  # Minimum number of proteins. Essentially leakiness.\n",
    "max_divisions = 50 # number of division events recorded for each intensity. \n",
    "partition_prob = 0.5 # \n",
    "alpha_std =  10\n",
    "I_tot_std = 0.05 # Fraction o f intensity.\n",
    "# Set up a DataFrame to store the relevant values.\n",
    "df = pd.DataFrame(columns=['seeded_alpha', 'simulated_alpha', 'alpha_std', 'N_1',\n",
    "                           'N_2', 'I_1', 'I_2'])\n",
    "\n",
    "# Loop through each intensity value. \n",
    "for i, I_tot in enumerate(int_range):\n",
    "    # Loop through each division event. \n",
    "    random_div_num = np.random.choice(np.arange(0, max_divisions,1))\n",
    "    for div in range(random_div_num):\n",
    "        # Set the noise in the alpha value. \n",
    "        alpha_noise = np.random.normal(alpha, 10)  # Add some gaussian norm. \n",
    "        \n",
    "        # Apply noise to the intensity.\n",
    "        I_tot = np.random.normal(I_tot, I_tot_std * I_tot)\n",
    "        \n",
    "        # Compute the number that are partitioned. \n",
    "        N_tot = int(I_tot / alpha_noise)\n",
    "        if N_tot < min_Ntot:\n",
    "            N_tot = int(min_Ntot)\n",
    "        N_1 = np.sum(np.random.rand(N_tot) < partition_prob).astype(int)\n",
    "        \n",
    "        # Compute the square difference. \n",
    "        square_diff = (alpha_noise * (N_1 - N_tot + N_1))**2\n",
    "        \n",
    "        # Add everything to the DataFrame.\n",
    "        df = df.append({'seeded_alpha': alpha, 'simulated_alpha': alpha_noise,\n",
    "                        'alpha_std': alpha_std, 'N_1': N_1, 'N_2': N_1 - N_tot,\n",
    "                        'I_1': N_1 * alpha_noise, 'I_2': (N_tot - N_1) * alpha_noise,\n",
    "                        }, ignore_index=True)\n",
    " \n",
    "# Save the DataFrame as a csv file. \n",
    "df.to_csv('../../data/other/simulated_dilution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bokeh' has no attribute 'charts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5dcc9c073b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set the figure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m p = bokeh.charts.Scatter(df, x='I_tot', y='square_diff', height=500,\n\u001b[0m\u001b[1;32m      4\u001b[0m                          \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mother cell intensity [a.u]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'squared intensity difference [a.u.]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bokeh' has no attribute 'charts'"
     ]
    }
   ],
   "source": [
    "# Set the figure. \n",
    "p = bokeh.plotting.figure()\n",
    "p = bokeh.charts.Scatter(df, x='I_tot', y='square_diff', height=500,\n",
    "                         width=600, xlabel='mother cell intensity [a.u]',\n",
    "                         ylabel='squared intensity difference [a.u.]', \n",
    "                         color='black', marker='circle')\n",
    "p.background_fill_color = '#E3DCD'\n",
    "p.grid.grid_line_color = 'white'\n",
    "p.grid.grid_line_dash = 'dotted'\n",
    "bokeh.models.BasicTickFormatter(use_scientific=False)\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A bayesian approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both the Brewster & Rosenfeld papers, the calibration factor was computed by binning the division event data and then fitting the function. Obviously, the number of bins chosen and the bin centers will introduce some degree of bias into the end result. Brewster and Franz got away with this because they computed the calibration factor as a function of events per bin, and found that at high events per bin the calibration factor reached a plateau. They arbitrarily chose some value in this range for allo f their calculations. As far as I can tell, the binning used in Rosenfeld *et al.* is unkown and belongs to the sands of time. \n",
    "\n",
    "Rather than doing the same approach, I can try to use a Bayesian approach to estimate withe parameter without the bias of binning. We can begin by writing down Bayes's theorem as\n",
    "\n",
    "$$\n",
    "P(\\alpha, \\sigma, N_1, N_\\text{tot} \\vert I_1, I_2) \\propto P(I_1, I_2 \\vert \\alpha, \\sigma, N_1, N_\\text{tot}) P(\\alpha, \\sigma, N_\\text{tot})P(N_1 \\vert N_\\text{tot}),\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the calibration factor, $N_1$ is the number of proteins in daughter cell 1, $I_1$ and $I_2$ are the intensities for daughter 1 and daughter 2, and $\\sigma$ is the uncertainty in our system. \n",
    "\n",
    "<br/>\n",
    "### Likelihoods\n",
    "\n",
    "There are three likelihoods in this system. We can say that for the intensities, $I_1$ and $I_2$, the values will be Gaussian distributed about some mean value, allow us to write\n",
    "\n",
    "$$\n",
    "P(I_1 \\vert \\alpha, \\sigma, N_1, N_\\text{tot}) = {1 \\over \\sqrt{2 \\pi \\sigma^2}}\\exp\\left[-{(I_1 - \\alpha N_1)^2 \\over 2\\sigma^2}\\right]\n",
    "$$\n",
    "and\n",
    "\n",
    "$$P(I_2 \\vert \\alpha, \\sigma, N_1, N_\\text{tot}) = {1 \\over \\sqrt{2 \\pi \\sigma^2}}\\exp\\left[-{(I_2 - \\alpha(N_\\text{tot} - N_1))^2 \\over 2\\sigma^2}\\right].\n",
    "$$\n",
    "\n",
    "Our last likelihood is for the nubmer of proteins in daughter 1. This, as the crux of this method, must be binomially distributed giving us a likelihood of \n",
    "\n",
    "$$\n",
    "P(N_1 \\vert N_\\text{tot}) = {{N_\\text{tot}}\\choose{N_1}}{1 \\over 2}^{N_\\text{tot}},\n",
    "$$\n",
    "\n",
    "assuming that the proteins are randomly distributed, $p= 1/2$.\n",
    "<br />\n",
    "### Priors\n",
    "\n",
    "As $\\sigma$ is the only scale parameter in our posteriror, we can give it a Jeffrey's prior\n",
    "\n",
    "$$\n",
    "P(\\sigma) = {1 \\over \\sigma}.\n",
    "$$\n",
    "\n",
    "The other priors can be of any value, and therefore have uniform priors. However, $N_1$ and $N_2$ must be discrete since these are tangible physical objects. Intensity can be continuous, however. \n",
    "\n",
    "### Full posterior\n",
    "\n",
    "With all of the pieces in hand, we can write the full posteriro probability distribution for a set of $i$ division events as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\alpha, \\sigma, &\\{N_1, N_\\text{tot}\\} \\vert \\{I_1, I_2\\}) \\propto \\\\ \n",
    "&{1 \\over \\sigma} \\left(\\prod\\limits_{i}^{N_\\text{div}}{{N_{i, \\text{tot}}}\\choose{N_{i,1}}}2^{-N_{i, \\text{tot}}}\\right)\\\\\n",
    "&\\left({1 \\over \\sqrt{2 \\pi \\sigma^2}}\\right)^{N_\\text{div}}\\left(\\exp\\left[{1 \\over 2\\sigma^2}\\sum\\limits_{i}^{N_\\text{div}}\\left((I_{i, 1} - \\alpha N_{i,1})^2 + (I_{i, 2} - \\alpha(N_{i,\\text{tot}} - N_{i, 1}))^2\\right)\\right]\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With this in hand, we can code the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neg_log_post(p, I_1, I_2):\n",
    "    \n",
    "    # Ensure that the parameters are physical.\n",
    "    if (p < 0).any():\n",
    "        return -np.inf\n",
    "    \n",
    "    # Unpack the parameters. \n",
    "    alpha, n_1, n_tot, sigma = p\n",
    "    n_div = len(n1)\n",
    "    n_1 = int(n_1)\n",
    "    n_tot = int(n_tot)\n",
    "    \n",
    "    # Make sure the numbers are correct. \n",
    "    if n_1 > n_tot:\n",
    "        return -np.inf\n",
    "    \n",
    "    # Compute the prior for sigma.\n",
    "    log_prior = -np.log(sigma)\n",
    "    \n",
    "    # Compute the likelihood for n_tot.\n",
    "    log_like_ntot = np.sum(scipy.special.gammaln(n_tot+1) -\\\n",
    "                           scipy.special.gammaln(n_1 +1) -\\\n",
    "                          scipy.special.gammaln(n_tot - n_1 + 1))\n",
    "    \n",
    "    log_like_int = -n_div * np.log(sigma) +\\\n",
    "                    np.log(np.sum((I_1 - alpha * n_1)**2 +\\\n",
    "                                  (I_2 - alpha * (n_tot - n_1))))\n",
    "        \n",
    "    return -(log_like_ntot + log_like_int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2627) into shape (2627,2626)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-acd94051b187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_walkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mseed_alpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m                                        \u001b[0mseed_alpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_walkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_walkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'N_tot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_walkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'I_tot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed_alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2627) into shape (2627,2626)"
     ]
    }
   ],
   "source": [
    "# Set the MCMC parameters\n",
    "n_div = len(df['N_1'])\n",
    "n_walkers = len(df['N_1'])\n",
    "n_dim = 2 * len(df['N_1'])\n",
    "n_burn = 3000\n",
    "seed_alpha = df['seed_alpha'].unique()[0]\n",
    "\n",
    "# Sprinkle around our starting positions. \n",
    "p = np.empty((n_walkers, n_dim))\n",
    "p[:, 0] = seed_alpha + np.random.uniform(-seed_alpha * 0.1,\\\n",
    "                                        seed_alpha * 0.1, n_walkers)\n",
    "p[:, 1:len(df['N_1'])] = df['N_1'] + np.random.uniform(-0.1, 0.1, n_walkers) \n",
    "p[:, len(df['N_1']):] = df['N_tot'] + np.random.uniform(-0.1, 0.1, n_walkers) \n",
    "np.random.uniform(df['I_tot'] / df['seed_alpha'])\n",
    "n_2 = np.random.uniform(df['I_tot'] / dt['seed_alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
